import streamlit as st
from datetime import datetime
import base64
import io
from PIL import Image

# å¯¼å…¥æœºå™¨äººä»£ç†ç›¸å…³æ¨¡å—
try:
    from langgraph.graph import StateGraph, START, END
    from langgraph.prebuilt.chat_agent_executor import AgentState
    from langgraph.graph.message import add_messages
    from langgraph.store.base import BaseStore
    from langchain_core.runnables import RunnableConfig
    from langchain_core.messages import BaseMessage
    from agent.AgentGraph.utils.image_chain import image_chain
    from typing import TypedDict, Union, Annotated, Sequence
    from robot_function.operator import Operator

    # åˆå§‹åŒ–æ“ä½œå™¨
    operator = Operator()
    operator.display()
    operator.init_sam()
    ROBOT_AGENT_AVAILABLE = True
except ImportError as e:
    ROBOT_AGENT_AVAILABLE = False
    print(f"Robot agent modules not available: {e}")

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="URgrasp Chat",
    page_icon="ğŸ¤–",
    layout="wide"
)

# æœºå™¨äººçŠ¶æ€å®šä¹‰
if ROBOT_AGENT_AVAILABLE:
    class RobotState(AgentState):
        """The state of the robot"""
        question: str
        encoded_image: str
        object_number: int
        place_number: int

    class RobotOutputState(TypedDict):
        """The output state of the robot"""
        object_number: int
        place_number: int
        messages: Annotated[Sequence[BaseMessage], add_messages]

    # å›¾åƒè¯†åˆ«èŠ‚ç‚¹
    def image_recognition_node(
        state: RobotState, config: RunnableConfig, store: BaseStore
    ) -> RobotState:
        res = image_chain.invoke(
            {"question": state["question"],
                "encoded_image": state["encoded_image"]}
        )
        return {"object_number": res["object_number"], "place_number": res["place_number"]}

    # æŠ“å–èŠ‚ç‚¹
    def pick_node(state: RobotState):
        operator.pick(state["object_number"])

    # æ”¾ç½®èŠ‚ç‚¹
    def place_node(state: RobotState):
        operator.place(state["place_number"])

    # æ„å»ºå·¥ä½œæµ
    graph = StateGraph(state_schema=RobotState, output=RobotOutputState)
    graph.add_node("image_recognition_node", image_recognition_node)
    graph.add_node("pick_node", pick_node)
    graph.add_node("place_node", place_node)
    graph.add_edge(START, "image_recognition_node")
    graph.add_edge("image_recognition_node", "pick_node")
    graph.add_edge("pick_node", "place_node")
    graph.add_edge("place_node", END)

    robot_agent = graph.compile()

# è™šæ‹Ÿæ¨¡å‹åˆ—è¡¨å’Œurl (æ–°å¢æ›´å¤šæ¨¡å‹é€‰é¡¹)
MODEL_OPTIONS = {
    "URgrasp Robot Agent": "robot://localhost/agent",

}

# æ¨¡å‹å¯¹åº”çš„å›¾æ ‡
MODEL_ICONS = {
    "URgrasp Robot Agent": "âœ¨",
}

# åˆå§‹åŒ–session state
if "selected_model" not in st.session_state:
    st.session_state.selected_model = "URgrasp Robot Agent" if ROBOT_AGENT_AVAILABLE else "GPT-4"
if "conversations" not in st.session_state:
    st.session_state.conversations = {"æ–°å¯¹è¯": []}
if "current_conv" not in st.session_state:
    st.session_state.current_conv = "æ–°å¯¹è¯"
if "uploaded_image" not in st.session_state:
    st.session_state.uploaded_image = None

# è¾…åŠ©å‡½æ•°ï¼šå¤„ç†æœºå™¨äººä»£ç†


def process_robot_agent_request(user_input, encoded_image=None):
    """å¤„ç†æœºå™¨äººä»£ç†è¯·æ±‚"""
    if not ROBOT_AGENT_AVAILABLE:
        return "âŒ æœºå™¨äººä»£ç†æ¨¡å—ä¸å¯ç”¨ã€‚è¯·ç¡®ä¿å·²å®‰è£…æ‰€éœ€ä¾èµ–ã€‚"

    try:
        if not encoded_image:
            # å°è¯•è·å–æ“ä½œå™¨çš„æ ‡æ³¨å›¾åƒ
            try:
                encoded_image = operator.get_annotated_image()
            except Exception as e:
                return f"âŒ æ— æ³•è·å–æ‘„åƒå¤´å›¾åƒ: {str(e)}"

        results = []
        results.append("ğŸ¤– **URgraspæœºå™¨äººä»£ç†å¤„ç†ä¸­...**\n")
        results.append(f"ğŸ“ **ç”¨æˆ·æŒ‡ä»¤**: {user_input}\n")

        # æ‰§è¡Œæœºå™¨äººä»£ç†æµç¨‹
        for chunk in robot_agent.stream(
            {
                "question": user_input,
                "encoded_image": encoded_image,
            },
            stream_mode="updates",
        ):
            if chunk:
                for node_name, node_output in chunk.items():
                    if node_name == "image_recognition_node":
                        if "object_number" in node_output and "place_number" in node_output:
                            results.append(f"ğŸ‘ï¸ **å›¾åƒè¯†åˆ«å®Œæˆ**:")
                            results.append(
                                f"   - ç›®æ ‡ç‰©ä½“ID: {node_output['object_number']}")
                            results.append(
                                f"   - æ”¾ç½®ä½ç½®ID: {node_output['place_number']}\n")

                    elif node_name == "pick_node":
                        results.append("ğŸ”§ **æ‰§è¡ŒæŠ“å–åŠ¨ä½œ**")
                        results.append(
                            f"   - æŠ“å–ç‰©ä½“ID: {node_output.get('object_number', 'æœªçŸ¥')}\n")

                    elif node_name == "place_node":
                        results.append("ğŸ“ **æ‰§è¡Œæ”¾ç½®åŠ¨ä½œ**")
                        results.append(
                            f"   - æ”¾ç½®ä½ç½®ID: {node_output.get('place_number', 'æœªçŸ¥')}\n")

        results.append("âœ… **ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼**")
        return "\n".join(results)

    except Exception as e:
        return f"âŒ **æœºå™¨äººä»£ç†æ‰§è¡Œé”™è¯¯**: {str(e)}"


def encode_image(image):
    """å°†PILå›¾åƒç¼–ç ä¸ºbase64å­—ç¬¦ä¸²"""
    buffered = io.BytesIO()
    image.save(buffered, format="PNG")
    return base64.b64encode(buffered.getvalue()).decode()


# è‡ªå®šä¹‰CSSæ ·å¼ - GPTå®˜ç½‘é£æ ¼ (ä¿æŒåŸæœ‰æ ·å¼)
st.markdown("""
<style>
/* å…¨å±€æ ·å¼ */
.stApp {
    background-color: #f9f9f9;
}

/* ä¾§è¾¹æ æ ·å¼ */
section[data-testid="stSidebar"] {
    background-color: #f7f7f8;
    width: 260px !important;
    border-right: 1px solid #e5e5e5;
}

section[data-testid="stSidebar"] > div {
    padding: 0;
    height: 100vh;
}

/* Logoæ ·å¼ - é»‘è‰²å¹¶ä¸ä¾§è¾¹æ æ”¶ç¼©æŒ‰é’®åŒè¡Œ */
.logo-container {
    display: flex;
    align-items: center;
    justify-content: space-between;
    padding: 12px 20px;
    background-color: transparent;
    position: relative;
    height: 56px;
}

.logo {
    color: #000000;
    font-size: 20px;
    font-weight: 600;
    font-family: -apple-system, BlinkMacSystemFont, sans-serif;
    margin-left: 40px;
}

/* ä¾§è¾¹æ å†…å®¹å®¹å™¨ */
.sidebar-content {
    padding: 16px;
    display: flex;
    flex-direction: column;
    gap: 12px;
}

/* æ–°å»ºå¯¹è¯æŒ‰é’® */
.new-chat-btn {
    background-color: transparent;
    border: 1px solid #c5c5d2;
    color: #000000;
    padding: 12px 16px;
    border-radius: 8px;
    cursor: pointer;
    font-size: 14px;
    transition: all 0.15s;
    text-align: center;
    width: 100%;
    display: flex;
    align-items: center;
    justify-content: center;
    gap: 8px;
}

.new-chat-btn:hover {
    background-color: #ececec;
}

/* å†å²å¯¹è¯æ ‡é¢˜ */
.history-title {
    text-align: center;
    color: #666;
    font-size: 14px;
    font-weight: 500;
    margin: 8px 0 4px 0;
}

/* å¯¹è¯é¡¹æ ·å¼ */
.conversation-item {
    background-color: transparent;
    border: none;
    color: #000000;
    padding: 12px 16px;
    border-radius: 8px;
    cursor: pointer;
    font-size: 14px;
    text-align: left;
    transition: all 0.15s;
    width: 100%;
    white-space: nowrap;
    overflow: hidden;
    text-overflow: ellipsis;
    margin-bottom: 2px;
}

.conversation-item:hover {
    background-color: #ececec;
}

.conversation-item.active {
    background-color: #ececec;
    font-weight: 500;
}

/* ä¸»å†…å®¹åŒºåŸŸæ ·å¼ */
.main-container {
    display: flex;
    flex-direction: column;
    max-width: 800px;
    margin: 0 auto;
    position: relative;
}

.header {
    padding: 16px 24px;
    display: flex;
    align-items: center;
    justify-content: space-between;
    background-color: transparent;
    border: none;
}

/* èŠå¤©å®¹å™¨ - ä¿®å¤åº•éƒ¨é—´è·é—®é¢˜ */
.chat-container {
    flex: 1;
    overflow-y: auto;
    padding: 20px 24px 140px 24px; /* å¢åŠ åº•éƒ¨paddingï¼Œä¸ºè¾“å…¥æ¡†å’Œä¿¡æ¯æç¤ºç•™å‡ºç©ºé—´ */
}

.chat-message {
    display: flex;
    padding: 20px 0;
    border-bottom: 1px solid #f0f0f0;
}

.chat-message:last-child {
    border-bottom: none;
}

.message-avatar {
    width: 36px;
    height: 36px;
    border-radius: 6px;
    display: flex;
    align-items: center;
    justify-content: center;
    margin-right: 16px;
    font-size: 18px;
    flex-shrink: 0;
}

.user-avatar {
    background-color: #10a37f;
    color: white;
}

.assistant-avatar {
    background-color: #6366f1;
    color: white;
}

.message-content {
    flex: 1;
    color: #374151;
    line-height: 1.6;
    font-size: 16px;
    font-family: -apple-system, BlinkMacSystemFont, sans-serif;
}

/* è¾“å…¥æ¡†å®¹å™¨ - å›ºå®šåœ¨åº•éƒ¨ï¼Œç§»é™¤ç™½æ¡é®æŒ¡ */
.input-container {
    position: fixed;
    bottom: 40px; /* ä¸ºä¿¡æ¯æç¤ºæ¡†ç•™å‡ºç©ºé—´ */
    left: 260px;
    right: 0;
    background: transparent;
    padding: 16px 0;
    z-index: 100;
}

.input-wrapper {
    max-width: 800px;
    margin: 0 auto;
    padding: 0 24px;
}

/* ä¿¡æ¯æç¤ºæ¡†æ ·å¼ - å›ºå®šåœ¨æœ€åº•éƒ¨ï¼Œæ¢å¤åŸæ¥æ ·å¼ */
.info-container {
    position: fixed;
    bottom: 0;
    left: 260px;
    right: 0;
    background: white;
    padding: 8px 0;
    z-index: 99;
}

.info-wrapper {
    max-width: 800px;
    margin: 0 auto;
    padding: 0 24px;
}

/* è°ƒæ•´èŠå¤©è¾“å…¥æ¡†æ ·å¼ */
.stChatInput {
    background-color: white;
    border: 1px solid #d9d9e3;
    border-radius: 8px;
}

/* éšè—é»˜è®¤streamlitå…ƒç´  */
#MainMenu {display: none;}
header[data-testid="stHeader"] {display: none;}
.stDeployButton {display: none;}

/* è°ƒæ•´ä¸»å†…å®¹åŒºåŸŸpadding */
.main .block-container {
    padding: 0;
    max-width: 100%;
}

/* ä¾§è¾¹æ æŒ‰é’®æ ·å¼ç»Ÿä¸€ */
section[data-testid="stSidebar"] button {
    width: 100%;
    border: none;
    background-color: transparent;
    color: #000000;
    border-radius: 8px;
    padding: 12px 16px;
    font-size: 14px;
    text-align: left;
    margin-bottom: 2px;
    transition: all 0.15s;
}

section[data-testid="stSidebar"] button:hover {
    background-color: #ececec;
}

/* æ´»è·ƒçŠ¶æ€çš„æŒ‰é’® */
section[data-testid="stSidebar"] button[data-active="true"] {
    background-color: #ececec;
    font-weight: 500;
}

/* è°ƒæ•´é¡¶éƒ¨é—´è· */
section.main > div:first-child {
    padding-top: 0 !important;
}

/* å»é™¤é¡¶éƒ¨ç©ºç™½ */
.stApp > header {
    display: none;
}

.stApp > div > div {
    padding-top: 0;
}

[data-testid="stAppViewContainer"] {
    padding-top: 0;
}

/* å›¾åƒä¸Šä¼ åŒºåŸŸæ ·å¼ */
.image-upload-area {
    border: 2px dashed #d9d9e3;
    border-radius: 8px;
    padding: 20px;
    text-align: center;
    margin: 10px 0;
    background-color: #f9f9f9;
}
</style>
""", unsafe_allow_html=True)

# ä¾§è¾¹æ 
with st.sidebar:
    # Logoå®¹å™¨
    st.markdown("""
    <div class="logo-container">
        <div class="logo">URgrasp</div>
    </div>
    """, unsafe_allow_html=True)

    # ä¾§è¾¹æ å†…å®¹
    st.markdown('<div class="sidebar-content">', unsafe_allow_html=True)

    # æ–°å»ºå¯¹è¯æŒ‰é’®
    if st.button("â• æ–°å»ºå¯¹è¯", key="new_chat", help="åˆ›å»ºæ–°å¯¹è¯", use_container_width=True):
        conv_count = len(st.session_state.conversations)
        name = f"å¯¹è¯ {conv_count + 1}"
        st.session_state.conversations[name] = []
        st.session_state.current_conv = name
        st.session_state.uploaded_image = None  # æ¸…é™¤ä¸Šä¼ çš„å›¾åƒ
        st.rerun()

    # å†å²å¯¹è¯æ ‡é¢˜
    st.markdown('<div class="history-title">å†å²å¯¹è¯</div>',
                unsafe_allow_html=True)

    # å†å²å¯¹è¯åˆ—è¡¨
    for conv_name in list(st.session_state.conversations.keys()):
        messages = st.session_state.conversations[conv_name]
        if messages and len(messages) > 0:
            display_name = messages[0]['content'][:20] + "..." if len(
                messages[0]['content']) > 20 else messages[0]['content']
        else:
            display_name = conv_name

        is_active = st.session_state.current_conv == conv_name

        if st.button(
            display_name,
            key=f"conv_{conv_name}",
            help=f"åˆ‡æ¢åˆ°: {conv_name}",
            use_container_width=True
        ):
            st.session_state.current_conv = conv_name
            st.rerun()

    # æœºå™¨äººçŠ¶æ€æ˜¾ç¤º
    if ROBOT_AGENT_AVAILABLE and st.session_state.selected_model == "URgrasp Robot Agent":
        st.markdown("---")
        st.markdown("### ğŸ¤– æœºå™¨äººçŠ¶æ€")
        st.success("âœ… æœºå™¨äººä»£ç†å·²è¿æ¥")
        st.info("ğŸ“· æ‘„åƒå¤´å°±ç»ª")

        # å›¾åƒä¸Šä¼ é€‰é¡¹ï¼ˆç”¨äºæµ‹è¯•ï¼‰
        st.markdown("### ğŸ“¸ å›¾åƒè¾“å…¥")
        uploaded_file = st.file_uploader(
            "ä¸Šä¼ æµ‹è¯•å›¾åƒ", type=['png', 'jpg', 'jpeg'], key="image_upload")
        if uploaded_file is not None:
            image = Image.open(uploaded_file)
            st.image(image, caption="ä¸Šä¼ çš„å›¾åƒ", width=200)
            st.session_state.uploaded_image = encode_image(image)

    st.markdown('</div>', unsafe_allow_html=True)

# ä¸»å†…å®¹åŒºåŸŸ
st.markdown('<div class="main-container">', unsafe_allow_html=True)

# é¡¶éƒ¨æ ‡é¢˜å’Œæ¨¡å‹é€‰æ‹©å™¨
col1, col2, col3 = st.columns([2, 3, 2])
with col2:
    st.markdown("""
    <div class="header">
        <h3 style="margin: 0; color: #374151; text-align: center;">URgrasp Chat</h3>
    </div>
    """, unsafe_allow_html=True)

# æ¨¡å‹é€‰æ‹©å™¨
with st.container():
    col1, col2, col3 = st.columns([1, 2, 1])
    with col2:
        available_models = list(MODEL_OPTIONS.keys())
        if not ROBOT_AGENT_AVAILABLE:
            available_models = [
                model for model in available_models if model != "URgrasp Robot Agent"]

        selected_model = st.selectbox(
            "é€‰æ‹©æ¨¡å‹",
            options=available_models,
            index=available_models.index(
                st.session_state.selected_model) if st.session_state.selected_model in available_models else 0,
            key="model_selector",
            label_visibility="collapsed"
        )
        st.session_state.selected_model = selected_model

# èŠå¤©å®¹å™¨
st.markdown('<div class="chat-container">', unsafe_allow_html=True)

messages = st.session_state.conversations[st.session_state.current_conv]

if not messages:
    if selected_model == "URgrasp Robot Agent":
        st.markdown("""
        <div style="text-align: center; padding: 60px 20px; color: #6b7280;">
            <h2 style="color: #374151; margin-bottom: 16px;">ğŸ¤– URgrasp æœºå™¨äººä»£ç†</h2>
            <p>æˆ‘æ˜¯æ‚¨çš„æ™ºèƒ½æœºå™¨äººåŠ©æ‰‹ï¼Œå¯ä»¥å¸®åŠ©æ‚¨è¿›è¡Œç‰©ä½“è¯†åˆ«ã€æŠ“å–å’Œæ”¾ç½®æ“ä½œï¼</p>
            <p style="font-size: 14px; margin-top: 20px;">
                <strong>æ”¯æŒçš„åŠŸèƒ½ï¼š</strong><br>
                â€¢ ğŸ“· å®æ—¶å›¾åƒè¯†åˆ«<br>
                â€¢ ğŸ”§ ç²¾ç¡®ç‰©ä½“æŠ“å–<br>
                â€¢ ğŸ“ æ™ºèƒ½ä½ç½®æ”¾ç½®<br>
            </p>
            <p style="font-size: 14px; margin-top: 20px; color: #10a37f;"><strong>å½“å‰æ¨¡å‹: URgrasp Robot Agent</strong></p>
        </div>
        """, unsafe_allow_html=True)
    else:
        st.markdown("""
        <div style="text-align: center; padding: 60px 20px; color: #6b7280;">
            <h2 style="color: #374151; margin-bottom: 16px;">ğŸ‘‹ æ¬¢è¿ä½¿ç”¨ URgrasp Chat</h2>
            <p>å¼€å§‹ä¸€ä¸ªæ–°çš„å¯¹è¯ï¼Œæˆ‘æ¥å¸®åŠ©ä½ è§£å†³é—®é¢˜ï¼</p>
            <p style="font-size: 14px; margin-top: 20px;">å½“å‰æ¨¡å‹: <strong>{}</strong></p>
        </div>
        """.format(selected_model), unsafe_allow_html=True)
else:
    for i, message in enumerate(messages):
        if message['role'] == 'user':
            avatar_class = "user-avatar"
            avatar_icon = "ğŸ‘¤"
        else:
            avatar_class = "assistant-avatar"
            # æ ¹æ®å½“å‰é€‰æ‹©çš„æ¨¡å‹æ˜¾ç¤ºä¸åŒçš„å›¾æ ‡
            avatar_icon = MODEL_ICONS.get(st.session_state.selected_model, "ğŸ¤–")

        st.markdown(f"""
        <div class="chat-message">
            <div class="message-avatar {avatar_class}">
                {avatar_icon}
            </div>
            <div class="message-content">
                {message['content']}
            </div>
        </div>
        """, unsafe_allow_html=True)

st.markdown('</div>', unsafe_allow_html=True)

# è¾“å…¥æ¡†å®¹å™¨ - å›ºå®šåœ¨åº•éƒ¨
st.markdown('<div class="input-container"><div class="input-wrapper">',
            unsafe_allow_html=True)

# ç”¨æˆ·è¾“å…¥
user_input = st.chat_input("è¾“å…¥ä½ çš„æ¶ˆæ¯...")

st.markdown('</div></div>', unsafe_allow_html=True)

# ä¿¡æ¯æç¤ºå®¹å™¨ - ç§»åˆ°æœ€åº•éƒ¨å¹¶ç§»é™¤èƒŒæ™¯
st.markdown('<div class="info-container"><div class="info-wrapper">',
            unsafe_allow_html=True)

# ä¿¡æ¯æç¤º
if selected_model == "URgrasp Robot Agent":
    if ROBOT_AGENT_AVAILABLE:
        st.success(f"ğŸ¤– **{selected_model}** å·²å°±ç»ª | æ”¯æŒå®æ—¶å›¾åƒè¯†åˆ«å’Œæœºå™¨äººæ§åˆ¶")
    else:
        st.error("âŒ æœºå™¨äººä»£ç†ä¸å¯ç”¨ | è¯·æ£€æŸ¥ä¾èµ–å®‰è£…")
else:
    st.info(
        f"å½“å‰æ¨¡å‹: **{selected_model}** | APIç«¯ç‚¹: `{MODEL_OPTIONS[selected_model]}`")

st.markdown('</div></div>', unsafe_allow_html=True)
st.markdown('</div>', unsafe_allow_html=True)

# å¤„ç†ç”¨æˆ·è¾“å…¥
if user_input:
    messages = st.session_state.conversations[st.session_state.current_conv]
    messages.append({"role": "user", "content": user_input})

    # æ ¹æ®é€‰æ‹©çš„æ¨¡å‹ç”Ÿæˆä¸åŒçš„å›å¤
    if selected_model == "URgrasp Robot Agent":
        # ä½¿ç”¨æœºå™¨äººä»£ç†å¤„ç†è¯·æ±‚
        encoded_image = st.session_state.uploaded_image if st.session_state.uploaded_image else None
        assistant_response = process_robot_agent_request(
            user_input, encoded_image)
    else:
        # æ¨¡æ‹Ÿå…¶ä»–AIæ¨¡å‹å›å¤
        api_url = MODEL_OPTIONS[selected_model]
        model_icon = MODEL_ICONS.get(selected_model, "ğŸ¤–")
        assistant_response = f"æˆ‘æ˜¯ {selected_model} æ¨¡å‹ {model_icon}ã€‚ä½ åˆšæ‰è¯´ï¼š\"{user_input}\"\n\nè¿™æ˜¯ä¸€ä¸ªæ¨¡æ‹Ÿå›å¤ã€‚å®é™…éƒ¨ç½²æ—¶ï¼Œè¿™é‡Œä¼šè°ƒç”¨ {api_url} æ¥è·å–çœŸå®çš„AIå›å¤ã€‚"

    messages.append({"role": "assistant", "content": assistant_response})
    st.rerun()
